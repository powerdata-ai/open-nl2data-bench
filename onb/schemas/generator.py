"""
Schema DDL generator for multiple database backends.

This module generates DDL (Data Definition Language) scripts for different databases:
- PostgreSQL
- MySQL
- ClickHouse
- Apache Doris

Usage:
    python -m onb.schemas.generator --database postgresql --output data/schemas/postgresql

    # Or generate all databases at once:
    python -m onb.schemas.generator --all

    # Direct Python usage:
    from onb.schemas.generator import SchemaGenerator
    generator = SchemaGenerator()
    generator.export_all_databases("ecommerce")
"""

import argparse
from pathlib import Path
from typing import Literal

from sqlalchemy import create_engine, event
from sqlalchemy.schema import CreateTable

from onb.schemas.base import Base

# Import all models to register them with metadata
import onb.schemas.ecommerce  # noqa: F401

DatabaseType = Literal["postgresql", "mysql", "clickhouse", "doris"]


class SchemaGenerator:
    """
    Generate DDL scripts for multiple database backends.

    This generator uses SQLAlchemy's schema reflection to generate
    database-specific CREATE TABLE statements from Python ORM models.
    """

    # Database connection strings (strategy='mock' means no actual connection)
    DIALECTS = {
        "postgresql": "postgresql://",
        "mysql": "mysql+pymysql://",
        "clickhouse": "clickhouse+native://",  # Requires clickhouse-sqlalchemy
        "doris": "mysql+pymysql://",  # Doris is MySQL-compatible
    }

    def __init__(self, output_dir: str = "data/schemas"):
        """
        Initialize schema generator.

        Args:
            output_dir: Directory to save generated SQL files
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def generate_ddl(self, database: DatabaseType, scenario: str = "ecommerce") -> str:
        """
        Generate DDL for a specific database.

        Args:
            database: Target database type
            scenario: Scenario name (e.g., 'ecommerce')

        Returns:
            Complete DDL script as string
        """
        # Create mock engine for DDL generation
        engine = create_engine(
            self.DIALECTS[database],
            strategy="mock",
            executor=lambda sql, *_: None,
        )

        # Collect DDL statements
        ddl_statements = []

        # Add database-specific preamble
        ddl_statements.extend(self._get_database_preamble(database, scenario))

        # Generate CREATE TABLE statements for all tables
        for table in Base.metadata.sorted_tables:
            create_stmt = CreateTable(table).compile(engine)
            ddl_statements.append(str(create_stmt).strip() + ";")

        # Add database-specific postamble
        ddl_statements.extend(self._get_database_postamble(database))

        return "\n\n".join(ddl_statements)

    def _get_database_preamble(
        self, database: DatabaseType, scenario: str
    ) -> list[str]:
        """
        Get database-specific preamble statements.

        Args:
            database: Target database type
            scenario: Scenario name

        Returns:
            List of preamble SQL statements
        """
        preambles = {
            "postgresql": [
                f"-- PostgreSQL Schema for OpenNL2Data-Bench",
                f"-- Scenario: {scenario}",
                "-- Generated by SchemaGenerator",
                "",
                "-- Connection settings",
                "SET client_encoding = 'UTF8';",
                "SET standard_conforming_strings = on;",
                "SET check_function_bodies = false;",
                "SET xmloption = content;",
                "SET client_min_messages = warning;",
                "SET row_security = off;",
                "",
                f"-- Create schema if not exists",
                f"CREATE SCHEMA IF NOT EXISTS {scenario};",
                f"SET search_path TO {scenario}, public;",
                "",
            ],
            "mysql": [
                f"-- MySQL Schema for OpenNL2Data-Bench",
                f"-- Scenario: {scenario}",
                "-- Generated by SchemaGenerator",
                "",
                "-- Connection settings",
                "SET NAMES utf8mb4;",
                "SET character_set_client = utf8mb4;",
                "SET FOREIGN_KEY_CHECKS = 0;",
                "",
                f"-- Create database if not exists",
                f"CREATE DATABASE IF NOT EXISTS {scenario} DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;",
                f"USE {scenario};",
                "",
            ],
            "clickhouse": [
                f"-- ClickHouse Schema for OpenNL2Data-Bench",
                f"-- Scenario: {scenario}",
                "-- Generated by SchemaGenerator",
                "",
                "-- Note: ClickHouse has different design principles than OLTP databases",
                "-- - Foreign keys are not enforced (used for documentation only)",
                "-- - Consider using MergeTree engine family for production",
                "-- - Partition by date columns for better query performance",
                "",
                f"-- Create database if not exists",
                f"CREATE DATABASE IF NOT EXISTS {scenario};",
                f"USE {scenario};",
                "",
            ],
            "doris": [
                f"-- Apache Doris Schema for OpenNL2Data-Bench",
                f"-- Scenario: {scenario}",
                "-- Generated by SchemaGenerator",
                "",
                "-- Note: Apache Doris is MySQL-compatible",
                "-- - Consider data distribution and partitioning for large tables",
                "-- - Use appropriate table models (Duplicate/Aggregate/Unique)",
                "",
                "SET NAMES utf8mb4;",
                "SET FOREIGN_KEY_CHECKS = 0;",
                "",
                f"-- Create database if not exists",
                f"CREATE DATABASE IF NOT EXISTS {scenario};",
                f"USE {scenario};",
                "",
            ],
        }
        return preambles.get(database, [])

    def _get_database_postamble(self, database: DatabaseType) -> list[str]:
        """
        Get database-specific postamble statements.

        Args:
            database: Target database type

        Returns:
            List of postamble SQL statements
        """
        postambles = {
            "mysql": [
                "",
                "-- Re-enable foreign key checks",
                "SET FOREIGN_KEY_CHECKS = 1;",
            ],
            "doris": [
                "",
                "-- Re-enable foreign key checks",
                "SET FOREIGN_KEY_CHECKS = 1;",
            ],
        }
        return postambles.get(database, [""])

    def export_to_file(
        self,
        database: DatabaseType,
        scenario: str = "ecommerce",
        filename: str | None = None,
    ) -> Path:
        """
        Export DDL to SQL file.

        Args:
            database: Target database type
            scenario: Scenario name
            filename: Custom filename (default: {scenario}_schema.sql)

        Returns:
            Path to generated SQL file
        """
        # Generate DDL
        ddl = self.generate_ddl(database, scenario)

        # Determine output path
        if filename is None:
            filename = f"{scenario}_schema.sql"

        output_path = self.output_dir / database / filename
        output_path.parent.mkdir(parents=True, exist_ok=True)

        # Write to file
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(ddl)

        return output_path

    def export_all_databases(self, scenario: str = "ecommerce") -> dict[str, Path]:
        """
        Export DDL for all supported databases.

        Args:
            scenario: Scenario name

        Returns:
            Dictionary mapping database type to output file path
        """
        results = {}

        for database in self.DIALECTS.keys():
            try:
                output_path = self.export_to_file(database, scenario)
                results[database] = output_path
                print(f"✅ Generated {database} schema: {output_path}")
            except Exception as e:
                print(f"❌ Failed to generate {database} schema: {e}")
                results[database] = None

        return results

    def create_all_tables(
        self, database: DatabaseType, connection_string: str
    ) -> None:
        """
        Directly create all tables in a database (for testing/development).

        Args:
            database: Target database type
            connection_string: Actual database connection string

        Example:
            generator.create_all_tables(
                "postgresql",
                "postgresql://user:pass@localhost:5432/test_db"
            )
        """
        engine = create_engine(connection_string)
        Base.metadata.create_all(engine)
        print(f"✅ Created all tables in {database}")

    def get_table_count(self) -> int:
        """
        Get total number of tables in the schema.

        Returns:
            Number of tables
        """
        return len(Base.metadata.tables)

    def get_table_list(self) -> list[str]:
        """
        Get list of all table names.

        Returns:
            List of table names
        """
        return sorted(Base.metadata.tables.keys())

    def print_summary(self) -> None:
        """Print schema summary."""
        print(f"\n{'='*60}")
        print(f"Schema Summary")
        print(f"{'='*60}")
        print(f"Total tables: {self.get_table_count()}")
        print(f"\nTables:")
        for i, table_name in enumerate(self.get_table_list(), 1):
            print(f"  {i:2d}. {table_name}")
        print(f"{'='*60}\n")


def main() -> None:
    """CLI entry point for schema generator."""
    parser = argparse.ArgumentParser(
        description="Generate database schemas for OpenNL2Data-Bench"
    )
    parser.add_argument(
        "--database",
        type=str,
        choices=["postgresql", "mysql", "clickhouse", "doris"],
        help="Target database type",
    )
    parser.add_argument(
        "--scenario",
        type=str,
        default="ecommerce",
        help="Scenario name (default: ecommerce)",
    )
    parser.add_argument(
        "--output",
        type=str,
        default="data/schemas",
        help="Output directory (default: data/schemas)",
    )
    parser.add_argument(
        "--all",
        action="store_true",
        help="Generate schemas for all databases",
    )
    parser.add_argument(
        "--summary",
        action="store_true",
        help="Print schema summary",
    )

    args = parser.parse_args()

    # Initialize generator
    generator = SchemaGenerator(output_dir=args.output)

    # Print summary if requested
    if args.summary:
        generator.print_summary()
        return

    # Generate schemas
    if args.all:
        print(f"Generating schemas for all databases...")
        print(f"Scenario: {args.scenario}")
        print(f"Output directory: {args.output}\n")
        results = generator.export_all_databases(args.scenario)

        # Print results
        print(f"\nGeneration complete!")
        print(f"{'='*60}")
        for database, path in results.items():
            if path:
                print(f"✅ {database:12s}: {path}")
            else:
                print(f"❌ {database:12s}: Failed")
        print(f"{'='*60}")

    elif args.database:
        print(f"Generating schema for {args.database}...")
        print(f"Scenario: {args.scenario}")
        print(f"Output directory: {args.output}\n")
        output_path = generator.export_to_file(args.database, args.scenario)
        print(f"\n✅ Generated: {output_path}")

    else:
        parser.print_help()
        print("\nError: Please specify --database or use --all")
        exit(1)


if __name__ == "__main__":
    main()
